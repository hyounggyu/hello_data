{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import dask.dataframe as dd\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Polars: https://pola-rs.github.io/polars/user-guide/io/parquet/\n",
    "- Dask: https://docs.dask.org/en/latest/dataframe-parquet.html\n",
    "- DuckDB: https://duckdb.org/docs/data/parquet/overview.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_df = pl.read_parquet(\"./data/parquet/*.parquet\")\n",
    "pl_df.filter((pl.col(\"date\") == pl.lit(date(2023, 12, 22))) & (pl.col(\"close\") >= 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_lazy_df = pl.scan_parquet(\"./data/parquet/*.parquet\")\n",
    "pl_lazy_df.filter((pl.col(\"date\") == pl.lit(date(2023, 12, 22))) & (pl.col(\"close\") >= 1.5)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_df = dd.read_parquet(\"./data/parquet/*.parquet\")\n",
    "dd_df[(dd_df[\"date\"] == date(2023, 12, 22)) & (dd_df[\"close\"] >= 1.5)].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE = \"./data/parquet/*.parquet\"\n",
    "duckdb.query(f\"\"\"SELECT * FROM '{TABLE}' WHERE date = '2023-12-22' AND close >= 1.5\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_final_df = pl_df.pivot(index=\"ticker\", columns=\"date\", values=\"close\").with_columns(\n",
    "    pl.concat_list(pl.all().exclude(\"ticker\")).alias(\"allclose\")\n",
    ")\n",
    "pl_final_df.write_parquet(\"./tmp/polars.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_df = dd.read_parquet(\"./data/parquet/*.parquet\")\n",
    "\n",
    "# Make date column to categorical to use pivot method\n",
    "dd_df.date = dd_df.date.dt.strftime(\"%Y-%m-%d\").astype(\"category\").cat.as_known()\n",
    "dd_pivot_df = dd_df.pivot_table(index='ticker', columns='date', values='close')\n",
    "\n",
    "# Aggregate the date columns\n",
    "dd_agg_df = dd_df.groupby('ticker').agg(list).drop(columns=\"date\")\n",
    "\n",
    "# Merge the two dataframes\n",
    "dd_final_df = dd_pivot_df.merge(dd_agg_df, on=\"ticker\").compute()\n",
    "\n",
    "dd_final_df.rename(columns={\"close\": \"allclose\"}, inplace=True)\n",
    "\n",
    "dd_final_df.to_parquet(\"./tmp/dask.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE = \"./data/parquet/*.parquet\"\n",
    "OUTPUT = \"./tmp/duckdb.parquet\"\n",
    "\n",
    "# Directly join the results of the two queries using subqueries\n",
    "duckdb.query(f\"\"\"\n",
    "COPY (\n",
    "    SELECT pivot_t.*, agg_t.allclose\n",
    "    FROM (\n",
    "        PIVOT '{TABLE}' ON date USING first(close) GROUP BY ticker\n",
    "    ) AS pivot_t\n",
    "    INNER JOIN (\n",
    "        SELECT ticker, list(close ORDER BY date ASC) AS allclose \n",
    "        FROM '{TABLE}' \n",
    "        GROUP BY ticker\n",
    "    ) AS agg_t ON pivot_t.ticker = agg_t.ticker\n",
    ") TO '{OUTPUT}' (FORMAT PARQUET)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(\"./tmp/dask.parquet\", engine=\"pyarrow\", dtype_backend=\"pyarrow\").compute()\n",
    "pl.from_pandas(df, schema_overrides={\"allclose\": pl.List(pl.Float64)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dd.read_parquet(\"./tmp/dask.parquet\", engine=\"pyarrow\", dtype_backend=\"pyarrow\").compute()\n",
    "df = dd.read_parquet(\"./tmp/dask.parquet\").compute()\n",
    "df.to_parquet(\"tmp/tmp.parquet\")\n",
    "# df = pd.read_parquet(\"tmp/tmp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dd.read_parquet(\"./tmp/polars.parquet\", engine=\"pyarrow\", dtype_backend=\"pyarrow\").compute()\n",
    "df = dd.read_parquet(\"./tmp/polars.parquet\", engine=\"pyarrow\").compute()\n",
    "df.to_parquet(\"tmp/tmp.parquet\")\n",
    "pd.read_parquet(\"tmp/tmp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(\"./tmp/duckdb.parquet\", engine=\"pyarrow\").compute()\n",
    "df.to_parquet(\"tmp/tmp.parquet\")\n",
    "pd.read_parquet(\"tmp/tmp.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(\"./tmp/polars.parquet\").compute()\n",
    "pl.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(\"./tmp/polars.parquet\", engine=\"pyarrow\", dtype_backend=\"pyarrow\").compute()\n",
    "pl.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_parquet(\"./tmp/dask.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parquet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
